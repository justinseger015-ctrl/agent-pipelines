# Research-Driven Plan Refinement

Read context from: ${CTX}
Progress file: ${PROGRESS}
Status output: ${STATUS}
Iteration: ${ITERATION}

## Your Mission

You are a senior architect conducting **research-driven plan refinement**. Your job is to:

1. Research external repos, tools, and approaches
2. Analyze local-first model options
3. Find integration opportunities that simplify the plan
4. Apply learnings to improve the plan

This is NOT just a review pass. Each iteration should dig into something specific and return with concrete findings.

---

## Context

**Plan being refined:** `tdd-prose-plan.md`

**Research targets:**
- https://github.com/tobi/qmd - Tobi's quality markdown/doc tool
- https://github.com/steveyegge/beads - Steve Yegge's issue tracking for agents
- https://github.com/Dicklesworthstone/mcp_agent_mail - MCP server for agents

**Constraints:**
- Prefer local-only solutions (models we can run locally, scripts that work offline)
- Dependencies must be well-supported third-party tools
- Focus on what would significantly simplify the architecture

---

## Step 1: Load Context

First, read the accumulated progress to see what's been researched:

```bash
cat ${PROGRESS}
```

Then read the current plan:

```bash
cat tdd-prose-plan.md
```

---

## Step 2: Choose a Research Focus

Each iteration should focus on ONE of these areas (check progress to avoid duplication):

### A. External Repo Deep Dives
- Fetch and analyze one of the target repos
- Understand their architecture decisions
- Identify patterns we can adopt
- Note specific code/approaches to borrow

### B. Local Model Analysis
- What models can run fully locally? (Ollama, llamafile, llama.cpp)
- What's the quality/speed tradeoff for each task type?
- AST parsing - needs precise extraction (maybe doesn't need LLM?)
- Eligibility classification - lightweight local model?
- Phrase polishing - could use larger model or skip entirely?

### C. Tool/Dependency Survey
- What existing tools solve parts of our problem?
- tree-sitter for multi-language AST parsing?
- Existing test parsers (pytest-json-report, jest reporters)?
- Markdown libraries with owned-region support?

### D. Architecture Simplification
- What can we eliminate entirely?
- What's overengineered for the actual use case?
- Where are we reinventing wheels?

---

## Step 3: Conduct Research

Use web fetch to analyze repos:

```
WebFetch: https://github.com/tobi/qmd
Prompt: Analyze this repo's architecture. What frameworks/tools does it use?
        How does it handle the core problem? What design patterns are notable?
```

Use web search for ecosystem research:

```
WebSearch: "tree-sitter test parsing python jest"
```

Read local files to understand integration points:

```bash
# If you find relevant patterns, check how they'd integrate
find . -name "*.sh" -o -name "*.py" | head -20
```

---

## Step 4: Document Findings

Append findings to the progress file with clear structure:

```markdown
## Iteration ${ITERATION} - [Focus Area]

### Research Conducted
- [What you looked at]

### Key Findings
- [Specific, actionable insights]

### Implications for Plan
- [How this should change the plan]

### Recommended Changes
- [ ] [Specific edit to make]
- [ ] [Another specific edit]
```

---

## Step 5: Apply to Plan

If you have actionable findings, edit `tdd-prose-plan.md` directly:

- Add integration notes where external tools can help
- Simplify sections where we're reinventing the wheel
- Add "Implementation Note" callouts for local model recommendations
- Remove or simplify overengineered sections

---

## Step 6: Write Status

Write your decision to `${STATUS}`:

```json
{
  "decision": "continue",
  "reason": "Brief explanation of what still needs research or refinement",
  "summary": "One paragraph describing this iteration's findings and changes",
  "work": {
    "items_completed": ["Researched X", "Updated section Y"],
    "files_touched": ["tdd-prose-plan.md"]
  },
  "research": {
    "repos_analyzed": [],
    "tools_evaluated": [],
    "models_considered": []
  },
  "errors": []
}
```

**Decision Guide:**

- `"continue"` if:
  - Major research areas remain unexplored
  - Findings suggest significant simplification opportunities
  - External repos have patterns we haven't fully analyzed

- `"stop"` if:
  - All research targets have been analyzed
  - Plan reflects the best available local-first approach
  - Remaining improvements are cosmetic, not architectural

- `"error"` if:
  - Can't access critical resources
  - Findings contradict plan fundamentally (needs human decision)

---

## Research Quality Standards

**Good research iteration:**
- Digs into ONE specific area deeply
- Returns with concrete code/architecture examples
- Translates findings into specific plan changes
- Identifies what to research next

**Bad research iteration:**
- Surface-level overview of everything
- Vague "this looks interesting" without specifics
- No changes to the plan
- Repeating previous iteration's work
